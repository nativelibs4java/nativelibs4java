package com.nativelibs4java.ffmpeg.avcodec;
import org.bridj.Callback;
import org.bridj.Pointer;
import org.bridj.StructObject;
import org.bridj.ann.Field;
import org.bridj.ann.Library;
/**
 * <i>native declaration : libavcodec/avcodec.h</i><br>
 * This file was autogenerated by <a href="http://jnaerator.googlecode.com/">JNAerator</a>,<br>
 * a tool written by <a href="http://ochafik.free.fr/">Olivier Chafik</a> that <a href="http://code.google.com/p/jnaerator/wiki/CreditsAndLicense">uses a few opensource projects.</a>.<br>
 * For help, please visit <a href="http://nativelibs4java.googlecode.com/">NativeLibs4Java</a> or <a href="http://bridj.googlecode.com/">BridJ</a> .
 */
@Library("avcodec") 
public class AVPacket extends StructObject {
	public AVPacket() {
		super();
	}
	public AVPacket(Pointer pointer) {
		super(pointer);
	}
	/**
	 * Presentation timestamp in AVStream->time_base units; the time at which<br>
	 * the decompressed packet will be presented to the user.<br>
	 * Can be AV_NOPTS_VALUE if it is not stored in the file.<br>
	 * pts MUST be larger or equal to dts as presentation cannot happen before<br>
	 * decompression, unless one wants to view hex dumps. Some formats misuse<br>
	 * the terms dts and pts/cts to mean something different. Such timestamps<br>
	 * must be converted to true pts/dts before they are stored in AVPacket.
	 */
	@Field(0) 
	public long pts() {
		return this.io.getLongField(this, 0);
	}
	/**
	 * Presentation timestamp in AVStream->time_base units; the time at which<br>
	 * the decompressed packet will be presented to the user.<br>
	 * Can be AV_NOPTS_VALUE if it is not stored in the file.<br>
	 * pts MUST be larger or equal to dts as presentation cannot happen before<br>
	 * decompression, unless one wants to view hex dumps. Some formats misuse<br>
	 * the terms dts and pts/cts to mean something different. Such timestamps<br>
	 * must be converted to true pts/dts before they are stored in AVPacket.
	 */
	@Field(0) 
	public AVPacket pts(long pts) {
		this.io.setLongField(this, 0, pts);
		return this;
	}
	public final long pts_$eq(long pts) {
		pts(pts);
		return pts;
	}
	/**
	 * Decompression timestamp in AVStream->time_base units; the time at which<br>
	 * the packet is decompressed.<br>
	 * Can be AV_NOPTS_VALUE if it is not stored in the file.
	 */
	@Field(1) 
	public long dts() {
		return this.io.getLongField(this, 1);
	}
	/**
	 * Decompression timestamp in AVStream->time_base units; the time at which<br>
	 * the packet is decompressed.<br>
	 * Can be AV_NOPTS_VALUE if it is not stored in the file.
	 */
	@Field(1) 
	public AVPacket dts(long dts) {
		this.io.setLongField(this, 1, dts);
		return this;
	}
	public final long dts_$eq(long dts) {
		dts(dts);
		return dts;
	}
	/// C type : uint8_t*
	@Field(2) 
	public Pointer<java.lang.Byte > data() {
		return this.io.getPointerField(this, 2);
	}
	/// C type : uint8_t*
	@Field(2) 
	public AVPacket data(Pointer<java.lang.Byte > data) {
		this.io.setPointerField(this, 2, data);
		return this;
	}
	/// C type : uint8_t*
	public final Pointer<java.lang.Byte > data_$eq(Pointer<java.lang.Byte > data) {
		data(data);
		return data;
	}
	@Field(3) 
	public int size() {
		return this.io.getIntField(this, 3);
	}
	@Field(3) 
	public AVPacket size(int size) {
		this.io.setIntField(this, 3, size);
		return this;
	}
	public final int size_$eq(int size) {
		size(size);
		return size;
	}
	@Field(4) 
	public int stream_index() {
		return this.io.getIntField(this, 4);
	}
	@Field(4) 
	public AVPacket stream_index(int stream_index) {
		this.io.setIntField(this, 4, stream_index);
		return this;
	}
	public final int stream_index_$eq(int stream_index) {
		stream_index(stream_index);
		return stream_index;
	}
	@Field(5) 
	public int flags() {
		return this.io.getIntField(this, 5);
	}
	@Field(5) 
	public AVPacket flags(int flags) {
		this.io.setIntField(this, 5, flags);
		return this;
	}
	public final int flags_$eq(int flags) {
		flags(flags);
		return flags;
	}
	/**
	 * Duration of this packet in AVStream->time_base units, 0 if unknown.<br>
	 * Equals next_pts - this_pts in presentation order.
	 */
	@Field(6) 
	public int duration() {
		return this.io.getIntField(this, 6);
	}
	/**
	 * Duration of this packet in AVStream->time_base units, 0 if unknown.<br>
	 * Equals next_pts - this_pts in presentation order.
	 */
	@Field(6) 
	public AVPacket duration(int duration) {
		this.io.setIntField(this, 6, duration);
		return this;
	}
	public final int duration_$eq(int duration) {
		duration(duration);
		return duration;
	}
	/// C type : destruct_callback
	@Field(7) 
	public Pointer<AVPacket.destruct_callback > destruct() {
		return this.io.getPointerField(this, 7);
	}
	/// C type : destruct_callback
	@Field(7) 
	public AVPacket destruct(Pointer<AVPacket.destruct_callback > destruct) {
		this.io.setPointerField(this, 7, destruct);
		return this;
	}
	/// C type : destruct_callback
	public final Pointer<AVPacket.destruct_callback > destruct_$eq(Pointer<AVPacket.destruct_callback > destruct) {
		destruct(destruct);
		return destruct;
	}
	/// C type : void*
	@Field(8) 
	public Pointer<? > priv() {
		return this.io.getPointerField(this, 8);
	}
	/// C type : void*
	@Field(8) 
	public AVPacket priv(Pointer<? > priv) {
		this.io.setPointerField(this, 8, priv);
		return this;
	}
	/// C type : void*
	public final Pointer<? > priv_$eq(Pointer<? > priv) {
		priv(priv);
		return priv;
	}
	/// < byte position in stream, -1 if unknown
	@Field(9) 
	public long pos() {
		return this.io.getLongField(this, 9);
	}
	/// < byte position in stream, -1 if unknown
	@Field(9) 
	public AVPacket pos(long pos) {
		this.io.setLongField(this, 9, pos);
		return this;
	}
	public final long pos_$eq(long pos) {
		pos(pos);
		return pos;
	}
	/**
	 * Time difference in AVStream->time_base units from the pts of this<br>
	 * packet to the point at which the output from the decoder has converged<br>
	 * independent from the availability of previous frames. That is, the<br>
	 * frames are virtually identical no matter if decoding started from<br>
	 * the very first frame or from this keyframe.<br>
	 * Is AV_NOPTS_VALUE if unknown.<br>
	 * This field is not the display duration of the current packet.<br>
	 * * The purpose of this field is to allow seeking in streams that have no<br>
	 * keyframes in the conventional sense. It corresponds to the<br>
	 * recovery point SEI in H.264 and match_time_delta in NUT. It is also<br>
	 * essential for some types of subtitle streams to ensure that all<br>
	 * subtitles are correctly displayed after seeking.
	 */
	@Field(10) 
	public long convergence_duration() {
		return this.io.getLongField(this, 10);
	}
	/**
	 * Time difference in AVStream->time_base units from the pts of this<br>
	 * packet to the point at which the output from the decoder has converged<br>
	 * independent from the availability of previous frames. That is, the<br>
	 * frames are virtually identical no matter if decoding started from<br>
	 * the very first frame or from this keyframe.<br>
	 * Is AV_NOPTS_VALUE if unknown.<br>
	 * This field is not the display duration of the current packet.<br>
	 * * The purpose of this field is to allow seeking in streams that have no<br>
	 * keyframes in the conventional sense. It corresponds to the<br>
	 * recovery point SEI in H.264 and match_time_delta in NUT. It is also<br>
	 * essential for some types of subtitle streams to ensure that all<br>
	 * subtitles are correctly displayed after seeking.
	 */
	@Field(10) 
	public AVPacket convergence_duration(long convergence_duration) {
		this.io.setLongField(this, 10, convergence_duration);
		return this;
	}
	public final long convergence_duration_$eq(long convergence_duration) {
		convergence_duration(convergence_duration);
		return convergence_duration;
	}
	/// <i>native declaration : libavcodec/avcodec.h:982</i>
	public static abstract class destruct_callback extends Callback<destruct_callback > {
		public abstract void apply(Pointer<AVPacket > AVPacketPtr1);
	};
}
